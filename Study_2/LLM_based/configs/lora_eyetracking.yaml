model_name: "Qwen3-8B"
trust_remote_code: true

training:
  output_dir: "outputs/lora_eyetracking"
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 1
  learning_rate: 2e-4
  weight_decay: 0.0
  warmup_ratio: 0.03
  logging_steps: 10
  max_seq_length: 2800
  fp16: true
  bf16: false
  gradient_checkpointing: true

generation:
  max_new_tokens: 8
  temperature: 0.0
  top_p: 1.0
  repetition_penalty: 1.0

lora:
  r: 8
  alpha: 16
  dropout: 0.05
  bias: "none"
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
